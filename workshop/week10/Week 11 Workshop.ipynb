{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activity One\n",
    "\n",
    "The skeleton code below is created so that you can have a go at writing your own implementation of collaborative filtering.\n",
    "\n",
    "Collaborative filtering is a popular technique used in recommendation systems to personalise and improve user experiences. The concept behind collaborative filtering is to analyse the behaviour and preferences of a group of users to recommend items or content to another user based on their similarities with the group. This technique can be applied to various types of data, such as movies, music, books, and products. Collaborative filtering works by building a model that identifies patterns and similarities in user behaviour and then uses these patterns to predict what items a user is likely to enjoy. By leveraging the collective intelligence of a group, collaborative filtering algorithms can generate highly accurate recommendations, making it a powerful tool for e-commerce, content-based websites, and other recommendation-based systems. In this way, collaborative filtering enables businesses to offer personalised experiences to their users, which can lead to increased engagement, loyalty, and revenue.\n",
    "\n",
    "The pseudocode is explained as:\n",
    "\n",
    "1. Collect data on user preferences for a set of items.\n",
    "2. Represent the user preferences as a matrix, with each row representing a user and each column representing an item.\n",
    "3. Compute the similarity between each pair of users using a similarity metric, such as cosine similarity or Pearson correlation.\n",
    "4. For a target user, identify the top N most similar users based on the similarity metric.\n",
    "5. For each item the target user has not rated, predict the rating by computing the weighted average of the ratings given by the most similar users, where the weights are the similarities between the users and the target user.\n",
    "6. Recommend the top N items with the highest predicted ratings.\n",
    "\n",
    "HAVE A GO! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def similarity(user1, user2):\n",
    "    # Calculate the dot product of the two user vectors\n",
    "    dot_product = np.dot(user1, user2)\n",
    "    # Calculate the magnitude of the two user vectors\n",
    "    magnitude = np.sqrt(np.sum(user1 ** 2) * np.sum(user2 ** 2))\n",
    "    # Calculate the similarity between the two users\n",
    "    similarity = \n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_rating(user_ratings, movie_ratings):\n",
    "    # Find the indices of the users who rated the movie\n",
    "    rated_indices = np.where(movie_ratings != 0)[0]\n",
    "    # Get the ratings of the movie by the rated users\n",
    "    ratings = \n",
    "    # Get the user vectors of the rated users\n",
    "    rated_users = user_ratings[]\n",
    "    # Calculate the similarities between the rated users and the target user\n",
    "    similarities = [similarity(user_ratings[0], rated_users[i]) for i in range(len(rated_indices))]\n",
    "    # Calculate the weighted average of the ratings, using the similarities as weights\n",
    "    weighted_sum = np.dot(similarities, ratings)\n",
    "    weighted_sum /= np.sum(similarities)\n",
    "    return weighted_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended movies: ['Movie 1', 'Movie 2']\n"
     ]
    }
   ],
   "source": [
    "def recommend_movies(user_ratings):\n",
    "    # Get the number of users and movies\n",
    "    num_users, num_movies = \n",
    "    # Choose a target user to make recommendations for\n",
    "    target_user = 0\n",
    "    # Find the indices of the unwatched movies by the target user\n",
    "    unwatched_indices = np.where(user_ratings[target_user] == 0)[0]\n",
    "    # Predict the ratings for the unwatched movies\n",
    "    predicted_ratings = [predict_rating(user_ratings, user_ratings[:, movie_index]) for movie_index in unwatched_indices]\n",
    "    # Sort the movies by the predicted rating in descending order\n",
    "    sorted_indices = np.argsort(predicted_ratings)[::-1]\n",
    "    # Get the top 3 recommended movies\n",
    "    top_movies = \n",
    "    recommended_movies = [f\"Movie {i+1}\" for i in top_movies]\n",
    "    return recommended_movies\n",
    "\n",
    "# Create a sample ratings matrix\n",
    "ratings = np.array([[3, 0, 0, 5], [0, 4, 0, 3], [1, 0, 2, 4], [5, 0, 3, 0], [0, 2, 4, 0]])\n",
    "\n",
    "# Make movie recommendations for the target user\n",
    "recommended_movies = recommend_movies()\n",
    "\n",
    "# Print the recommended movies\n",
    "print(\"Recommended movies:\", recommended_movies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activity 2\n",
    "\n",
    "Now we will look at completing a few exercises related to recommendation systems from your textbook.\n",
    "\n",
    "**Exercise 9.2.1:** Three computers, A, B, and C, have the numerical features\n",
    "listed below:\n",
    "\n",
    "            Feature      A       B      C\n",
    "    Processor Speed   3.06    2.68   2.92\n",
    "    Disk Size          500     320    640\n",
    "    Main-Memory Size     6       4      6\n",
    "    \n",
    "We may imagine these values as defining a vector for each computer; for instance, A’s vector is [3.06, 500, 6]. We can compute the cosine distance between any two of the vectors, but if we do not scale the components, then the disk size will dominate and make differences in the other components essentially invisible. Let us use 1 as the scale factor for processor speed, α for the disk size, and β for the main memory size.\n",
    "\n",
    "(a) In terms of α and β, compute the cosines of the angles between the vectors\n",
    "for each pair of the three computers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 9.2.3:** A certain user has rated the three computers of Exercise 9.2.1 as follows: \n",
    "    A: 4 stars\n",
    "    B: 2 stars\n",
    "    C: 5 stars.\n",
    "    \n",
    "(a) Normalize the ratings for this user.\n",
    "\n",
    "(b) Compute a user profile for the user, with components for processor speed,\n",
    "disk size, and main memory size, based on the data of Exercise 9.2.1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        a    b    c    d    e    f    g    h\n",
    "    A   4    5         5    1         3    2\n",
    "    B        3    4    3    1    2    1\n",
    "    C   2         1    3         4    5    3\n",
    "\n",
    "    Figure 9.8: A utility matrix for exercises\n",
    "    \n",
    "    \n",
    "Exercise 9.3.1 : Figure 9.8 is a utility matrix, representing the ratings, on a 1–5 star scale, of eight items, a through h, by three users A, B, and C. Compute the following from the data of this matrix.\n",
    "\n",
    "(a) Treating the utility matrix as boolean, compute the Jaccard distance between each pair of users.\n",
    "\n",
    "(b) Repeat Part (a), but use the cosine distance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activity 3: UV Decomposition\n",
    "\n",
    "UV decomposition, also known as matrix factorization, is a technique used in collaborative filtering algorithms to predict user preferences. The technique involves breaking down a large user-item preference matrix into two smaller matrices: a user matrix and an item matrix.\n",
    "\n",
    "In UV decomposition, each row of the user matrix represents a user, and each column of the item matrix represents an item. The values in the matrices represent the degree to which each user likes each item.\n",
    "\n",
    "The goal of UV decomposition is to factorize the original preference matrix into two smaller matrices such that the product of the matrices approximates the original matrix. This can be achieved using various optimization techniques, such as gradient descent.\n",
    "\n",
    "The resulting user and item matrices can then be used to predict user preferences for new items. When a user expresses preferences for a set of items, the algorithm can compute a weighted average of the item vectors for those items, using the weights as the user's preferences.\n",
    "\n",
    "UV decomposition has become a popular approach for recommendation systems because it can handle large sparse matrices and can be used to make accurate predictions even when a user has rated only a small fraction of the items.\n",
    "\n",
    "The pseudocode for this method is as such:\n",
    "\n",
    "Input:\n",
    "\n",
    "    - A user-item preference matrix M with n rows (users) and m columns (items)\n",
    "    \n",
    "    - The number of latent factors k to use for the decomposition\n",
    "\n",
    "Output:\n",
    "\n",
    "- Two matrices U and V that together approximate the original matrix M\n",
    "\n",
    "   1. Initialize U and V to random values between 0 and 1\n",
    "\n",
    "   2. Repeat until convergence:\n",
    "   \n",
    "       a. Update U by minimizing the objective function:\n",
    "          \n",
    "          ||M - UV^T||^2 + lambda*(||U||^2 + ||V||^2)  using an optimization algorithm such as gradient descent\n",
    "          \n",
    "          \n",
    "       b. Update V by minimizing the same objective function, using U^T instead of U\n",
    "\n",
    "   3. Return the final U and V matrices\n",
    "\n",
    "   4. To make recommendations for a user u:\n",
    "       a. Compute the dot product of u's row in U and all columns in V\n",
    "       b. Sort the resulting scores in descending order\n",
    "       c. Recommend the top items to the user\n",
    "       \n",
    "Note that in step 2, lambda is a regularization parameter that helps prevent overfitting. It can be set using cross-validation or other techniques. Also, the optimization algorithm used to update U and V can vary depending on the specific application, with methods like stochastic gradient descent and alternating least squares being common choices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def uv_decomposition(R, k, learning_rate, regularization):\n",
    "    \"\"\"\n",
    "    Performs UV decomposition on the input matrix R, with a target rank of k, using stochastic gradient descent (SGD).\n",
    "    Returns the decomposed matrices U and V.\n",
    "    \"\"\"\n",
    "    # Initialize U and V with random values\n",
    "    num_users, num_items = R.shape\n",
    "    U = #num users by k\n",
    "    V = #k by num items\n",
    "\n",
    "    # Perform stochastic gradient descent to optimize U and V\n",
    "    for epoch in range(10):\n",
    "        for i in range(#users):\n",
    "            for j in range(#items):\n",
    "                if R[i, j] > 0:\n",
    "                    error = R[i, j] - np.dot(U[i, :], V[:, j])\n",
    "                    U[i, :] += learning_rate * (error * V[:, j] - regularization * U[i, :])\n",
    "                    V[:, j] += learning_rate * (error * U[i, :] - regularization * V[:, j])\n",
    "\n",
    "    # Return the decomposed matrices U and V\n",
    "    return U, V\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original R:\n",
      "[[5 3 0 1]\n",
      " [4 0 0 1]\n",
      " [1 1 0 5]\n",
      " [1 0 0 4]\n",
      " [0 1 5 4]]\n",
      "Reconstructed R:\n",
      "[[4.78189885 2.76868319 2.90291074 0.99591564]\n",
      " [3.76944354 2.21151163 2.49243155 1.00317761]\n",
      " [1.05026055 0.86071774 5.54756854 4.88243146]\n",
      " [0.98465631 0.67373038 4.5952831  3.86867847]\n",
      " [1.71396237 1.09959075 4.91030523 3.91255557]]\n"
     ]
    }
   ],
   "source": [
    "# Create a sample matrix R\n",
    "R = np.array([\n",
    "    [5, 3, 0, 1],\n",
    "    [4, 0, 0, 1],\n",
    "    [1, 1, 0, 5],\n",
    "    [1, 0, 0, 4],\n",
    "    [0, 1, 5, 4]\n",
    "])\n",
    "\n",
    "# Perform UV decomposition on R\n",
    "U, V = uv_decomposition(R, k=3, learning_rate=0.1, regularization=0.1)\n",
    "\n",
    "# Reconstruct the matrix R using the decomposed matrices U and V\n",
    "R_reconstructed = #get the dot product \n",
    "\n",
    "# Print the original matrix R and the reconstructed matrix R\n",
    "print(\"Original R:\")\n",
    "print(R)\n",
    "print(\"Reconstructed R:\")\n",
    "print(R_reconstructed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activity 4: Questions on Recommendation Systems\n",
    "\n",
    "Have a go at answering some of these questions from Big Data Fundamentals\n",
    "\n",
    "\n",
    "\n",
    "Big Data Fundamentals: Movie and music recommendations\n",
    "Quiz 16: Collaborative filtering\n",
    "\n",
    "    Instructions for Questions 5 and 6\n",
    "    Consider the following rating matrix:\n",
    "\n",
    "        A\tB\tC\tD\tE\n",
    "    U1\t1\t0\t1\t0\t1\n",
    "    U2\t1\t1\t1\t1\t1\n",
    "    U3\t1\t0\t0\t0\t1\n",
    "\n",
    "Calculate the Jaccard similarity between each of the users. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instructions for Questions 7 and 8\n",
    "Consider the following rating matrix:\n",
    "\n",
    "        A\tB\tC\tD\tE\n",
    "    U1\t1\t1\t1\t0\t1\n",
    "    U2\t1\t0\t1\t1\t0\n",
    "    U3\t1\t0\t1\t0\t1\n",
    "Calculate the Jaccard similarity between each of the users. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
